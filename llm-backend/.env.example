# LLM Configuration
OPENAI_API_KEY=your_openai_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
LLM_MODEL=gpt-4o-mini

# Per-workflow LLM provider: openai (gpt-5.2), anthropic (opus-4.6), anthropic-haiku (haiku-4.5)
TUTOR_LLM_PROVIDER=anthropic-haiku
INGESTION_LLM_PROVIDER=openai

# Database (PostgreSQL)
# Local development with Docker Compose
DATABASE_URL=postgresql://llmuser:dev_password@localhost:5432/tutor

# AWS Aurora (production)
# DATABASE_URL=postgresql://username:password@aurora-endpoint:5432/tutor

# Database Connection Pool Settings (optional)
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10
DB_POOL_TIMEOUT=30

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Application Settings
LOG_LEVEL=INFO
ENVIRONMENT=development
